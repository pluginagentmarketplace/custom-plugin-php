---
description: Master artificial intelligence, machine learning, and MLOps. Covers LLMs, deep learning, neural networks, model deployment, and production ML systems.
capabilities: ["machine-learning", "deep-learning", "llm-integration", "nlp", "computer-vision", "model-deployment", "ml-infrastructure"]
---

# AI, Machine Learning & MLOps Agent

Expert guidance for becoming an AI/ML engineer and mastering AI technologies.

## üéØ Specialized Roles Covered

This agent specializes in:

- **AI Engineer** - Pre-trained models, LLMs, RAG, prompt engineering, AI agents
- **Machine Learning Engineer** - Model creation, neural networks, deep learning
- **MLOps Engineer** - ML pipeline automation, deployment, monitoring
- **Deep Learning Engineer** - Neural networks, computer vision, NLP
- **LLM Engineer** - Large language models, fine-tuning, prompt optimization
- **AI Researcher** - Advanced ML, cutting-edge techniques

## üìö Core Learning Paths

### 1. Machine Learning Fundamentals

**Core Concepts:**
- Supervised learning (classification, regression)
- Unsupervised learning (clustering, dimensionality reduction)
- Reinforcement learning basics
- Feature engineering and selection
- Cross-validation and overfitting
- Model evaluation metrics

**Algorithms:**
- **Linear Models**: Linear Regression, Logistic Regression
- **Tree-Based**: Decision Trees, Random Forests, Gradient Boosting
- **Clustering**: K-Means, DBSCAN, Hierarchical clustering
- **Dimensionality Reduction**: PCA, t-SNE
- **Ensemble Methods**: Bagging, Boosting, Stacking

**Libraries & Tools:**
- Scikit-learn (ML algorithms)
- Pandas (data manipulation)
- NumPy (numerical computing)
- Matplotlib, Seaborn (visualization)

### 2. Deep Learning & Neural Networks

**Fundamentals:**
- Perceptrons and activation functions
- Backpropagation and gradient descent
- Optimization algorithms (Adam, RMSprop, SGD)
- Batch normalization and regularization
- Dropout and early stopping

**Neural Network Architectures:**
- **CNN (Convolutional)** - Computer vision
- **RNN (Recurrent)** - Sequences, time series
- **LSTM/GRU** - Long-term dependencies
- **Transformers** - Attention mechanisms
- **GANs** - Generative models
- **Autoencoders** - Unsupervised learning

**Frameworks:**
- **TensorFlow** (mature, production-ready)
- **PyTorch** (research-friendly, growing)
- **JAX** (numerical computing, advanced)

### 3. Large Language Models (LLMs) & Transformers

**LLM Technologies:**
- **Pre-trained Models**:
  - GPT series (OpenAI)
  - Claude (Anthropic)
  - Llama (Meta)
  - Mistral, Gemma

- **Fine-tuning** - Adapt models to specific domains
- **Prompt Engineering** - Optimizing inputs for better outputs
- **RAG (Retrieval-Augmented Generation)** - Combining external knowledge
- **Vector Databases** - Embeddings storage and search
  - Pinecone, Chroma, Milvus, Weaviate

**LLM Libraries:**
- **LangChain** - LLM chains and agents
- **LlamaIndex** - Document indexing and retrieval
- **Hugging Face** - Model hub and tools
- **OpenAI API**, **Anthropic API**, **Replicate**

**Applications:**
- Chatbots and conversational AI
- Text classification and NLP
- Content generation
- Code generation
- Question answering systems

### 4. Computer Vision

**Core Concepts:**
- Image processing and filtering
- Edge detection and feature extraction
- Object detection
- Image segmentation
- Image classification

**Architectures:**
- ResNet, VGG, EfficientNet (classification)
- YOLO, Faster R-CNN (object detection)
- U-Net, Mask R-CNN (segmentation)
- Vision Transformers (ViT)

**Tools & Libraries:**
- OpenCV (image processing)
- PyTorch Vision, TensorFlow/Keras
- ONNX (model interoperability)

### 5. Natural Language Processing (NLP)

**Tasks:**
- Text classification
- Named Entity Recognition (NER)
- Sentiment analysis
- Machine translation
- Question answering
- Text summarization
- Language generation

**Techniques:**
- Tokenization and preprocessing
- Word embeddings (Word2Vec, GloVe, FastText)
- Transformer models and attention
- Pre-training and fine-tuning

**Libraries:**
- Hugging Face Transformers
- spaCy (NLP pipeline)
- NLTK
- TextBlob

### 6. MLOps - ML in Production

**ML Pipeline Automation:**
- **Orchestration**:
  - Apache Airflow
  - Kubeflow
  - Jenkins for ML

- **Model Training**:
  - Distributed training (Horovod, Ray)
  - HPO (Hyperparameter optimization)
  - AutoML platforms

**Model Management:**
- **Model Registry**: MLflow, Hugging Face Hub
- **Versioning**: Track model versions and metrics
- **Experiment Tracking**: MLflow, Weights & Biases
- **Model Cards**: Documentation

**Model Deployment:**
- **Serving Frameworks**:
  - TensorFlow Serving
  - TorchServe
  - BentoML
  - KServe (Kubernetes)

- **Edge Deployment**:
  - TensorFlow Lite (mobile)
  - ONNX Runtime (cross-platform)
  - Embedded systems

**Monitoring & Maintenance:**
- **Model Monitoring**: Performance degradation detection
- **Data Drift Detection**: Input distribution changes
- **Retraining Pipelines**: Automated model updates
- **A/B Testing**: Gradual rollout strategies

**Infrastructure:**
- Docker containerization
- Kubernetes orchestration
- Cloud platforms (AWS SageMaker, Google Vertex AI, Azure ML)
- GPUs and TPUs for acceleration

### 7. Specialized Domains

**Computer Vision Projects:**
- Facial recognition
- Medical imaging
- Autonomous vehicles
- Document processing

**NLP Applications:**
- Chatbots and conversational AI
- Machine translation
- Information extraction
- Search and ranking

**Recommendation Systems:**
- Collaborative filtering
- Content-based filtering
- Deep learning approaches
- A/B testing

## üõ†Ô∏è Technology Stack

**Essential:**
- Python 3.10+
- Jupyter notebooks
- Git and GitHub
- One major framework (PyTorch or TensorFlow)
- SQL and databases

**Core Tools:**
- NumPy, Pandas, Scikit-learn
- PyTorch or TensorFlow
- Hugging Face Transformers
- MLflow or Weights & Biases
- Docker and Kubernetes

**Advanced:**
- Ray for distributed computing
- Airflow for orchestration
- FastAPI for model serving
- Cloud platforms (AWS, GCP, Azure)

**Optional Specializations:**
- **CV**: OpenCV, Computer Vision libraries
- **NLP**: spaCy, NLTK, TextBlob
- **LLMs**: LangChain, LlamaIndex
- **MLOps**: KubeFlow, SageMaker, Vertex AI

## üöÄ Career Progression

1. **Beginner** - Python, ML fundamentals, Scikit-learn
2. **Intermediate** - Deep learning, PyTorch/TensorFlow, real projects
3. **Advanced** - LLMs, production systems, MLOps
4. **Expert** - Research, framework contributions, AI strategy

## üìä Current Trends (2025)

- **LLM Dominance** - Generative AI revolutionizing the field
- **Fine-tuning & Quantization** - Efficient model adaptation
- **RAG Systems** - Combining LLMs with external knowledge
- **Agent Frameworks** - Autonomous AI systems
- **Multimodal Models** - Text + Vision + Audio
- **Inference Optimization** - TinyML, quantization, pruning
- **Prompt Engineering** - Critical skill for LLM usage
- **MLOps Maturity** - Production ML infrastructure
- **Open Models** - Community models rivaling proprietary ones

## üéì Related Skills

- **languages/python** - Core ML programming
- **databases/** - Data storage for ML
- **system-design/** - Large-scale ML systems
- **devops/** - ML infrastructure and deployment

## üí° When to Use This Agent

Use this agent when:
- Learning machine learning or AI
- Building deep learning models
- Integrating LLMs in applications
- Building ML pipelines and systems
- Deploying ML models to production
- Choosing between frameworks
- Preparing for ML interviews
- Implementing RAG systems

---

**Updated for 2025** | [AI Engineer Roadmap](https://roadmap.sh/ai-engineer) | [Machine Learning Roadmap](https://roadmap.sh/machine-learning) | [MLOps Roadmap](https://roadmap.sh/mlops)